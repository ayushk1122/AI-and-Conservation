{"cells":[{"cell_type":"markdown","metadata":{"id":"Mb5kPBtfHJtQ"},"source":["Write a function that takes just one argument — the name of the CSV file – and generates a\n","split of the images into train (70%), validation (15%) and test sets (15%). Each split should\n","have approximately the same proportion of giraffe images and zebra images (and images\n","containing both), but the images should be randomly assigned to the splits otherwise. Create\n","output that shows the split."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10828,"status":"ok","timestamp":1696349665089,"user":{"displayName":"Ayush Krishnappa","userId":"12760647574393520338"},"user_tz":240},"id":"ETHcqrnbT_nu","outputId":"baac91bf-2309-4342-ecca-974faa543fca"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/hw3-csci4946\n"]}],"source":["%cd /content/drive/MyDrive/hw3-csci4946/\n","!cp -r \"/content/drive/MyDrive/hw3-csci4946/images\" \"/content/images\"\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1057,"status":"ok","timestamp":1696349669717,"user":{"displayName":"Ayush Krishnappa","userId":"12760647574393520338"},"user_tz":240},"id":"C9-hUP5XHPHO","outputId":"396e87b4-5429-4f68-8dd9-1521d93e49f7"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Set: 3463 images\n","Validation Set: 742 images\n","Test Set: 743 images\n"]},{"data":{"text/plain":["(              filename  giraffe  zebra\n"," 151   000000000152.jpg        0      1\n"," 807   000000000808.jpg        0      1\n"," 621   000000000622.jpg        0      1\n"," 3978  000000003979.jpg        1      0\n"," 3998  000000003999.jpg        1      0\n"," ...                ...      ...    ...\n"," 37    000000000038.jpg        0      1\n"," 974   000000000975.jpg        0      1\n"," 3195  000000003196.jpg        0      1\n"," 983   000000000984.jpg        0      1\n"," 3838  000000003839.jpg        0      1\n"," \n"," [3463 rows x 3 columns],\n","               filename  giraffe  zebra\n"," 4001  000000004002.jpg        0      1\n"," 1418  000000001419.jpg        0      1\n"," 3332  000000003333.jpg        0      1\n"," 1560  000000001561.jpg        0      1\n"," 39    000000000040.jpg        0      1\n"," ...                ...      ...    ...\n"," 2762  000000002763.jpg        1      0\n"," 846   000000000847.jpg        0      1\n"," 2551  000000002552.jpg        0      1\n"," 2928  000000002929.jpg        0      1\n"," 117   000000000118.jpg        0      1\n"," \n"," [742 rows x 3 columns],\n","               filename  giraffe  zebra\n"," 645   000000000646.jpg        0      1\n"," 3     000000000004.jpg        0      1\n"," 4170  000000004171.jpg        0      1\n"," 467   000000000468.jpg        0      1\n"," 5     000000000006.jpg        1      0\n"," ...                ...      ...    ...\n"," 4426  000000004427.jpg        0      1\n"," 466   000000000467.jpg        0      1\n"," 3092  000000003093.jpg        0      1\n"," 3772  000000003773.jpg        0      1\n"," 860   000000000861.jpg        0      1\n"," \n"," [743 rows x 3 columns])"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","import numpy as np\n","\n","def generate_splits(csv_filename):\n","    df = pd.read_csv(csv_filename)\n","\n","    # splits data based on giraffe and zebra samples, splits into 70% training, 15% validation, 15% test\n","    train, validate, test = np.split(df.sample(frac=1, random_state=42),\n","                                     [int(.7*len(df)), int(.85*len(df))])\n","\n","    # prints the splits\n","    print(f\"Train Set: {len(train)} images\")\n","    print(f\"Validation Set: {len(validate)} images\")\n","    print(f\"Test Set: {len(test)} images\")\n","\n","    return train, validate, test\n","\n","generate_splits('metadata.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1696003434645,"user":{"displayName":"Ayush Krishnappa","userId":"12760647574393520338"},"user_tz":240},"id":"hpVSQ9PHroar","outputId":"e4bff505-f813-4398-8ed9-0490d5bbb7d4"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"]}],"source":["ls /content"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dQAuxcZxVk7b"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ka8ACeNiVk8u"},"outputs":[],"source":["!ls\n"]},{"cell_type":"markdown","metadata":{"id":"ZNti3eaeIg8o"},"source":["Write a subclass of the PyTorch Dataset class that implements the functionality to creates\n","datasets for your train, validation and test splits. The class should include transformations\n","to map your image into the appropriate format and to resize to the correct input size for your\n","network.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5TNKQYvFIjP9"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset\n","from torchvision import transforms\n","from PIL import Image\n","\n","class CustomDataset(Dataset): # inherits pytorch DataSet class\n","    def __init__(self, dataframe, root_dir, transform=None): # initializes dataset object using pandas data frame, image directory, and image transformations\n","        self.dataframe = dataframe\n","        self.root_dir = root_dir\n","        self.transform = transform\n","\n","    def __len__(self): # size of dataset\n","        return len(self.dataframe)\n","\n","\n","    def __getitem__(self, idx): # retrieves sample for given index, gets and loads image at given index\n","      img_name = self.dataframe.iloc[idx, 0]\n","      img_path = os.path.join(self.root_dir, img_name)\n","      image = Image.open(img_path)\n","\n","\n","      # retrieves labels for image, presence of zebra or giraffe\n","      label_giraffe = int(self.dataframe.iloc[idx, 1])\n","      label_zebra = int(self.dataframe.iloc[idx, 2])\n","      labels = torch.tensor([label_giraffe, label_zebra])\n","\n","      if self.transform:\n","          image = self.transform(image)\n","\n","      return image, labels, img_name  # Return filename here\n","\n","    # def __getitem__(self, idx):\n","    #     img_name = self.dataframe.iloc[idx, 0]\n","    #     img_path = os.path.join(self.root_dir, img_name)\n","    #     image = Image.open(img_path)\n","\n","    #     label_giraffe = int(self.dataframe.iloc[idx, 1])\n","    #     label_zebra = int(self.dataframe.iloc[idx, 2])\n","    #     labels = torch.tensor([label_giraffe, label_zebra]) # converts labels to pytorch tensor\n","\n","    #     if self.transform: # performs transformations on image\n","    #         image = self.transform(image)\n","\n","    #     return image, labels\n","\n","transform = transforms.Compose([ # transformation sequence, resizes images to 224x224\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","])\n"]},{"cell_type":"markdown","metadata":{"id":"AWHsJQRIOJRK"},"source":["Write code that tests your Dataset class by iterating through the three instances you created\n","to show they are disjoint and include all images from the provided directory."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23376,"status":"ok","timestamp":1696349702352,"user":{"displayName":"Ayush Krishnappa","userId":"12760647574393520338"},"user_tz":240},"id":"8F-mk_GuOKTy","outputId":"1e729808-6a57-4d9b-9a00-08331ecefa62"},"outputs":[{"name":"stdout","output_type":"stream","text":["Train Set: 3463 images\n","Validation Set: 742 images\n","Test Set: 743 images\n","All tests passed!\n"]}],"source":["import os\n","\n","\n","def test_datasets(root_dir, train, validate, test):\n","    # Create dataset instances\n","    train_dataset = CustomDataset(dataframe=train, root_dir=root_dir, transform=transform)\n","    val_dataset = CustomDataset(dataframe=validate, root_dir=root_dir, transform=transform)\n","    test_dataset = CustomDataset(dataframe=test, root_dir=root_dir, transform=transform)\n","\n","    # Create sets to collect filenames\n","    train_files = set()\n","    val_files = set()\n","    test_files = set()\n","\n","    # iterate over all instances\n","    for _, _, img_name in train_dataset:\n","        train_files.add(img_name)\n","\n","    for _, _, img_name in val_dataset:\n","        val_files.add(img_name)\n","\n","    for _, _, img_name in test_dataset:\n","        test_files.add(img_name)\n","\n","    # Check disjoint sets\n","    assert len(train_files & val_files) == 0, \"Overlap between train and validation sets\"\n","    assert len(train_files & test_files) == 0, \"Overlap between train and test sets\"\n","    assert len(val_files & test_files) == 0, \"Overlap between validation and test sets\"\n","\n","    # Check that all files in the directory are accounted for\n","    all_files = set(os.listdir(root_dir))\n","    all_dataset_files = train_files | val_files | test_files\n","    assert all_files == all_dataset_files, \"Not all files from the directory are included in the datasets\"\n","\n","    print(\"All tests passed!\")\n","\n","train, validate, test = generate_splits('metadata.csv')\n","\n","test_datasets('/content/images/images', train, validate, test)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"15_5-XKT8iRbB1TfMiUMz82b07mA9u6fS"},"executionInfo":{"elapsed":4111,"status":"ok","timestamp":1696349708958,"user":{"displayName":"Ayush Krishnappa","userId":"12760647574393520338"},"user_tz":240},"id":"r9ZkLcHgYpTz","outputId":"abee1f98-24e3-4222-ddd4-f2356575d860"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["import matplotlib.pyplot as plt\n","\n","def explore_dataset(dataset, title):\n","    # Caclulates image counts for zebras, giraffes, both, and neither\n","    giraffe_count = sum(dataset.dataframe.iloc[:, 1])\n","    zebra_count = sum(dataset.dataframe.iloc[:, 2])\n","    both_count = sum((dataset.dataframe.iloc[:, 1] & dataset.dataframe.iloc[:, 2]))\n","    neither_count = len(dataset) - giraffe_count - zebra_count + both_count\n","\n","    # Prints statistics\n","    print(f\"{title} - Number of Giraffes: {giraffe_count}\")\n","    print(f\"{title} - Number of Zebras: {zebra_count}\")\n","    print(f\"{title} - Number of Both: {both_count}\")\n","    print(f\"{title} - Number of Neither: {neither_count}\")\n","\n","    # Displays 10 random images, creates 2x5 subplots using random choice\n","    fig, axs = plt.subplots(2, 5, figsize=(15, 6))\n","    fig.suptitle(title)\n","    indices = np.random.choice(len(dataset), 10, replace=False)\n","    for i, idx in enumerate(indices):\n","        image, _, _ = dataset[idx]\n","        ax = axs[i//5, i%5]\n","        ax.imshow(transforms.ToPILImage()(image))\n","        ax.axis('off')\n","    plt.show()\n","\n","# creates instances again\n","train_dataset = CustomDataset(dataframe=train, root_dir='/content/drive/MyDrive/hw3-csci4946/images', transform=transform)\n","val_dataset = CustomDataset(dataframe=validate, root_dir='/content/drive/MyDrive/hw3-csci4946/images', transform=transform)\n","test_dataset = CustomDataset(dataframe=test, root_dir='/content/drive/MyDrive/hw3-csci4946/images', transform=transform)\n","for dataset, title in [(train_dataset, \"Train Dataset\"), (val_dataset, \"Validation Dataset\"), (test_dataset, \"Test Dataset\")]: # outputs formatted data\n","    explore_dataset(dataset, title)\n"]},{"cell_type":"markdown","metadata":{"id":"H5NJvB2_fUUm"},"source":["**Part 3**\n","\n","For Part 3, please implement and train a network to predict what species are\n","\n","\n","shown in an image.\n","In particular, the trained network should decide if an image shows zebras and decide if an image\n","shows giraffes. These decisions should be made independently, allowing the possibility of an image\n","having both zebras and giraffes. One way to do this might be to have a separate network for each\n","species, but this does not allow learning of common information. Instead you can form a combined\n","loss function, using BCEWithLogitsLoss\n","2\n","https://pytorch.org/docs/stable/generated/torch.nn.BCEWithLogitsLoss.html\n","This is just a combination of the cross-entropy loss values for zebras and giraffes separately.\n","Rather than building a network from PyTorch primitives, please use a pre-trained network\n","(architecture and weights) as a backbone and add a fully-connected network on top. Train only\n","this fully-connected network. Use the Dataset class you created for Part 2.\n","Submit a Jupyter notebook that shows your neural network model (class), the training and\n","testing functionality, and your final results. Please also show test images (at least 5 and maybe up\n","to 10) that were classified correctly and images that were classified incorrectly, both for zebras and\n","for giraffes. Doing this is important to help understand when and why the network succeeds and\n","fails, and it should be a regular part of your work."]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1yzCEB8FJ8fgN7gC1_f8eGdpm-Qtn2CTV"},"id":"t-Mnfe5xfWB3","executionInfo":{"status":"ok","timestamp":1696361021867,"user_tz":240,"elapsed":4018537,"user":{"displayName":"Ayush Krishnappa","userId":"12760647574393520338"}},"outputId":"d5c89d02-3ce7-43d6-b874-a0d94795d010"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# @title Default title text\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torchvision import models\n","from torch.utils.data import DataLoader\n","import matplotlib.pyplot as plt\n","\n","class CustomModel(nn.Module):\n","    def __init__(self):\n","        super(CustomModel, self).__init__()\n","        # Using pre-trained ResNet-50 model\n","        self.resnet = models.resnet50(pretrained=True)\n","\n","        # Freeze the ResNet layers\n","        for param in self.resnet.parameters():\n","            param.requires_grad = False\n","\n","        # Modify the final layer to have 2 output nodes (one for giraffe and one for zebra)\n","        self.resnet.fc = nn.Linear(self.resnet.fc.in_features, 2)\n","\n","    def forward(self, x):\n","        return self.resnet(x)\n","\n","def train_model(model, criterion, optimizer, train_loader, val_loader, epochs=10): # training function\n","    # makes model more efficient by running on GPU if available\n","    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","    model = model.to(device)\n","    for epoch in range(epochs):\n","        model.train() # sets model to training mode\n","        train_loss = 0.0\n","        for inputs, labels, _ in train_loader:\n","            optimizer.zero_grad()\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels.float())\n","            loss.backward()\n","            optimizer.step()\n","            train_loss += loss.item() * inputs.size(0)\n","\n","        model.eval() # evaluate model on validation set\n","        val_loss = 0.0\n","        with torch.no_grad():\n","            for inputs, labels, _ in val_loader:\n","                outputs = model(inputs)\n","                loss = criterion(outputs, labels.float())\n","                val_loss += loss.item() * inputs.size(0)\n","\n","        print(f\"Epoch {epoch+1}/{epochs} - Train loss: {train_loss/len(train_loader.dataset):.4f} - Val loss: {val_loss/len(val_loader.dataset):.4f}\")\n","\n","# Hyperparameters and setup\n","lr = 0.001 # step size\n","batch_size = 32\n","epochs = 3\n","\n","model = CustomModel()\n","criterion = nn.BCEWithLogitsLoss() # defines loss function\n","optimizer = optim.Adam(model.resnet.fc.parameters(), lr=lr) # Adam optemizer\n","\n","# loads datasets\n","train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","val_loader = DataLoader(val_dataset, batch_size=batch_size)\n","\n","# trains model using loaded datasets\n","train_model(model, criterion, optimizer, train_loader, val_loader, epochs)\n","\n","\n","def visualize_results(model, test_loader): # visualizes results on test data\n","    correct_zebra_imgs = []\n","    incorrect_zebra_imgs = []\n","    correct_giraffe_imgs = []\n","    incorrect_giraffe_imgs = []\n","\n","    model.eval() # evaluated model on test data\n","    with torch.no_grad():\n","        for inputs, labels, _ in test_loader:\n","            outputs = torch.sigmoid(model(inputs))\n","            preds = torch.round(outputs)\n","            for img, pred, label in zip(inputs, preds, labels):\n","                img = img.squeeze(0)  # Remove batch dimension\n","\n","                # Giraffes\n","                if pred[0] == label[0] and label[0] == 1:  # Correctly identified as giraffe\n","                    correct_giraffe_imgs.append(img)\n","                elif pred[0] != label[0] and label[0] == 1:  # Incorrectly identified as not giraffe\n","                    incorrect_giraffe_imgs.append(img)\n","\n","                # Zebras\n","                if pred[1] == label[1] and label[1] == 1:  # Correctly identified as zebra\n","                    correct_zebra_imgs.append(img)\n","                elif pred[1] != label[1] and label[1] == 1:  # Incorrectly identified as not zebra\n","                    incorrect_zebra_imgs.append(img)\n","\n","\n","    # empty list case\n","    def display_images(img_list, title): # displays images for each category\n","      if not img_list:  # Check if the list is empty\n","          print(f\"No images to display for '{title}'\")\n","          return\n","\n","      num_images = len(img_list)\n","\n","      # Determine number of rows and columns\n","      num_rows = num_images // 5 + int(num_images % 5 != 0)\n","      num_cols = min(num_images, 5)\n","\n","      fig, axs = plt.subplots(num_rows, num_cols, figsize=(15, 3*num_rows))\n","\n","      # Handle different structures of axs\n","      if num_rows == 1 and num_cols == 1:\n","          axs = [[axs]]\n","      elif num_rows == 1:\n","          axs = [axs]\n","\n","      fig.suptitle(title)\n","\n","      for i, img in enumerate(img_list):\n","          row_idx = i // 5\n","          col_idx = i % 5\n","          ax = axs[row_idx][col_idx]\n","\n","          ax.imshow(transforms.ToPILImage()(img))\n","          ax.axis('off')\n","      plt.tight_layout()\n","      plt.show()\n","\n","    # Displaying images\n","    display_images(correct_zebra_imgs[:5], \"Correctly Classified Zebras\")\n","    display_images(incorrect_zebra_imgs[:5], \"Incorrectly Classified Zebras\") # network seems to only have one incorrectly classified zebra image in test data\n","    display_images(correct_giraffe_imgs[:5], \"Correctly Classified Giraffes\")\n","    display_images(incorrect_giraffe_imgs[:5], \"Incorrectly Classified Giraffes\")\n","    print(\"Number of Correctly Classified Zebras\", len(correct_zebra_imgs))\n","    print(\"Number of Incorrectly Classified Zebras\", len(incorrect_zebra_imgs))\n","    print(\"Number of Correctly Classified Giraffes\", len(correct_giraffe_imgs))\n","    print(\"Number of Incorrectly Classified Gebras\", len(incorrect_zebra_imgs))\n","\n","# Visualizing results\n","test_loader = DataLoader(test_dataset, batch_size=1)\n","visualize_results(model, test_loader)\n","\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"LzPpxh1HwYZ_"},"outputs":[],"source":["\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-vnMtK37QUBL"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]}],"metadata":{"colab":{"provenance":[{"file_id":"1B3JMb-PoafqRge3BDbuSaC-QlJ0KHM1q","timestamp":1695994191586}],"mount_file_id":"1kfzChV_iEtZ3hZ1XBytE-k1WhmUXZkKD","authorship_tag":"ABX9TyOX6r/WmsZgaB/+PyZFLI2v"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}